# 第2章 企业级解决方案

## 1 小文件问题

**问题描述**：

由于在HDFS中，每一个小文件在NameNode中都会占用150字节的内存空间，而且每个小文件都是一个Block，会产生一个InputSplit，这样就会产生一个Map任务，同时启动多个Map任务消耗性能，影响MapReduce执行效率。

**解决方案**：

HDFS提供两种类型的容器，分别是SequenceFile和MapFile。

- SequenceFile：将<key,value>对序列化到文件中。
- MapFile：是排序后的SequenceFile，主要由两部分组成，分别是index和data；index作为文件的数据索引，主要记录了每个Record的key值，以及该Record在文件中的偏移位置。在MapFile被访问的时候，索引文件会被加载到内存，通过索引映射关系可迅速定位到指定Record所在文件位置，因此，相对SequenceFile而言，MapFile的检索效率是高效的，缺点是会消耗一部分内存来存储index数据。

## 2 数据倾斜问题

**问题描述**：

需要统计的数据很集中，比如有一个文件，有1000W条数据，这里面的值主要都是数字（1,2,3,4,5,6,7,8,9,10），希望统计出来每个数字出现的次数，其中值为5的数据有910w条左
右，剩下的9个数字一共只有90w条。

**解决方案**：

把倾斜的数据打散

1. 设置Reduce任务个数
```java
job.setNumReduceTasks(Integer.parseInt(args[2]));
```
2. 将数据打散
```java
String key = words[0];
if ("5".equals(key)) {
	//把倾斜的key打散，分成10份
	key = "5" + "_" + random.nextInt(10);
}
```

## 3 YARN 

### 3.1 YARN架构分析

- YARN主要负责集群资源的管理和调度，支持主从架构，主节点最多可以有2个，从节点可以有多个
- ResourceManager：主节点主要负责集群资源的分配和管理
- NodeManager：从节点主要负责当前机器资源管理

### 3.2 YARN资源管理模型

- YARN主要管理内存和CPU这两种资源类型
- NodeManager启动时，会向ResourceManager注册，注册信息中包含该节点可分配的CPU和内存总量
- yarn.nodemanager.resource.memory-mb：单节点可分配的物理内存总量，默认是8MB\*1024，即8G
- yarn.nodemanager.resource.cpu-vcores：单节点可分配的虚拟CPU个数，默认是8

### 3.3 YARN中的调度器
- FIFO Scheduler：先进先出（first in, first out）调度策略
- Capacity Scheduler：FIFO Scheduler的多队列版本
- Fair Scheduler：多队列，多用户共享资源

### 3.4 案例：YARN多资源队列配置和使用

**需求描述**：

增加2个队列，一个是online队列，一个是offline队列，然后向offline队列中提交一个mapreduce任务，其中online队列里面运行实时任务，offline队列里面运行离线任务

**解决方法**：

1. 修改`etc/hadoop`目录下的`capacity-scheduler.xml`配置文件
```xml
<property>
    <name>yarn.scheduler.capacity.root.queues</name>
    <value>default,online,offline</value>
    <description>
      The queues at the this level (root is the root queue).
    </description>
</property>
<property>
    <name>yarn.scheduler.capacity.root.default.capacity</name>
    <value>70</value>
    <description>Default queue target capacity.</description>
</property>
<property>
    <name>yarn.scheduler.capacity.root.online.capacity</name>
    <value>10</value>
    <description>Online queue target capacity.</description>
</property>
<property>
    <name>yarn.scheduler.capacity.root.offline.capacity</name>
    <value>20</value>
    <description>Offline queue target capacity.</description>
</property>
<property>
    <name>yarn.scheduler.capacity.root.default.maximum-capacity</name>
    <value>70</value>
    <description>
      The maximum capacity of the default queue.
    </description>
</property>
<property>
    <name>yarn.scheduler.capacity.root.online.maximum-capacity</name>
    <value>10</value>
    <description>
      The maximum capacity of the online queue.
    </description>
</property>
<property>
    <name>yarn.scheduler.capacity.root.offline.maximum-capacity</name>
    <value>20</value>
    <description>
      The maximum capacity of the offline queue.
    </description>
</property>
```

2. 重启Hadoop
```shell
stop-all.sh
start-all.sh
```