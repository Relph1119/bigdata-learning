# 第11章 Flink

## 1 Flink简介

- Flink是一个开源的分布式、高性能、高可用、准确的流处理框架
- Flink支持流处理和批处理

### 1.1 Flink架构

![Flink架构图](../images/ch11/01-flink-structure.png)

- DataStram API：支持复杂事件处理和table操作
- 对DatasetAPI：支持flinkML机器学习、Gelly图计算、table操作

### 1.2 Flink三大核心组件

- Data Source：数据源，负责接收数据
- Transformations：算子，负责对数据进行处理
- Data Sink：输出组件，负责将计算好的数据输出到其它存储介质中

### 1.3 Flink的流处理和批处理

- 流处理：当一条数据被处理完成后，序列化到缓存中，然后立刻通过网络传输到下一个节点，由下一个节点继续处理，即一条一条处理
- 批处理：当一条数据被处理完成后，序列化到缓存中，并不会立刻通过网络传输到下一个节点，当缓存写满的时候，就持久化到本地硬盘上，当所有数据都被处理完成后，才开始将处理后的数据通过网络传输到下一个节点
- Flink采用缓存块为单位的传输形式，如果缓存块的超时值为0，则为流处理（低延迟）；如果超时值为无限大，则为批处理（高吞吐量）

### 1.4 Storm vs SparkStreaming vs Flink

|   产品   |     Strom     | sparkStreaming |    Flink     |
| :------: | :-----------: | :------------: | :----------: |
|   模型   |    Native     |  Mirco-Batch   |    Native    |
|   API    |    组合式     |     声明式     |    声明式    |
|   语义   | At-least-once |  Exectly-once  | Exectly-once |
| 容错机制 |      Ack      |   Checkpoint   |  Checkpoint  |
| 状态管理 |      无       |  基于DStream   |   基于操作   |
|   延时   |      Low      |     Medium     |     Low      |
|  吞吐量  |      Low      |      High      |     High     |

### 1.5 选择实时计算框架的建议

1. 需要关注流数据是否需要进行状态管理
2. 消息语义是否有特殊要求At-least-once或者Exectly-once
3. 如果是小型独立的项目，需要低延迟的场景，建议使用Storm
4. 如果项目中已经使用了Spark，并且秒级别的实时处理可以满足需求，建议使用SparkStreaming
5. 要求消息语义为Exectly-once，数据量较大，要求高吞吐低延迟，需要进行状态管理，建议选择Flink

## 2 Flink Job开发步骤

1. 获得一个执行环境
2. 加载/创建 初始化数据
3. 指定操作数据的transaction算子
4. 指定数据目的地
5. 调用execute()触发执行程序

## 3 Flink部署

该部署方式为Flink ON YARN模式

![Flink ON YARN模式](../images/ch11/02-flink-on-yarn.png)

### 3.1 下载并解压安装包

访问[Flink官网](https://flink.apache.org/zh/downloads.html#flink)，下载flink-1.11.1-bin-scala_2.12.tgz安装包，在`/data/soft`目录下解压

```shell
cd /data/soft
tar -xvf flink-1.11.1-bin-scala_2.12.tgz
cd flink-1.11.1/conf
```

### 3.2 添加HADOOP_CLASS环境变量

在`/etc/profile`文件中添加如下内容
```shell
export HADOOP_CLASSPATH=`${HADOOP_HOME}/bin/hadoop classpath`
```

### 3.3 配置Flink日志
在conf目录下的`flink-conf.yaml`文件，修改以下内容：
```yaml
jobmanager.archive.fs.dir: hdfs://bigdata01:9000/completed-jobs/
historyserver.web.address: 192.168.56.101
historyserver.web.port: 8082
historyserver.archive.fs.dir: hdfs://bigdata01:9000/completed-jobs/
historyserver.archive.fs.refresh-interval: 10000
```

### 3.4 启动Flink日志进程
```shell
cd /data/soft/flink-1.11.1
bin/historyserver.sh start
```

### 3.5 创建Flink集群并提交任务
该命令可以创建一个临时的Flink集群，并提交任务
```shell
bin/flink run -m yarn-cluster -yjm 1024 -ytm 1024 ./examples/batch/WordCount.jar
```

## 4 Flink核心API

- 低级API(Stateful Stream Processing)：提供了对时间和状态的细粒度控制，简洁性和易用性较差，主要应用在一些复杂事件处理逻辑上。
- 核心API(DataStream/DataSet API)：主要提供了针对流数据和批数据的处理，是对低级API进行了一些封装，提供了filter、sum、max、min等高级函数。
- Table API：一般与DataSet或者DataStream紧密关联，可以通过一个DataSet或DataStream创建出一个Table，然后再使用类似于filter、join、select这种操作。最后还可以将一个Table对象转成DataSet或DataStream。
- SQL：Flink的SQL底层是基于Apache Calcite，Apache Calcite实现了标准的SQL，使用起来比其他API更加灵活，因为可以直接使用SQL语句。Table API和SQL可以很容易地结合在一块使用，因为它们都返回Table对象。

### 4.1 DataStream API

- DataStream API主要分为3块：DataSource、Transformation、DataSink
- DataSource：程序的输入数据源。
- Transformation：具体的操作，它对一个或多个输入数据源进行计算处理，例如map、flatMap和filter等操作。
- DataSink：程序的输出，它可以把Transformation处理之后的数据输出到指定的存储介质中。

#### 4.1.1 Transformation

- `union`：合并多个流，多个流的数据类型必须一致
- `connect`：只能连接两个流，两个流的数据类型可以不同
- `split`：根据规则把一个数据流切分为多个流
- `shuffle`：随机分区
- `rebalance`：对数据集进行再平衡，重分区，消除数据倾斜
- `rescale`：重分区
- `partitionCustom`：自定义分区

#### 4.1.2 DataSink

- `writeAsText()`：将元素以字符串形式逐行写入，这些字符串通过调用每个元素的`toString()`方法来获取
- `print()`：打印每个元素的`toString()`方法的值到标准输出
- 提供了一些Connectors，可以实现输出到第三方组件中

### 4.2 DataSet API

#### 4.2.1 DataSource

- 基于集合：fromCollection(Collection)
- 基于文件：readTextFile(path)

#### 4.2.2 Transformation

- `distinct`：返回数据集中去重之后的元素
- `join`：内连接
- `outerJoin`：外连接
- `cross`：获取两个数据集的笛卡尔积
- `union`：返回多个数据集的总和，数据类型需要一致
- `first-n`：获取集合中的前N个元素

### 4.3 Table API

1. 使用DataStream创建表，主要包含下面两种情况
    - 使用DataStream创建view视图
    - 使用DataS创建table对象

2. 使用DataSet创建表

	注意：此时只能使用旧的执行引擎，新的Blink执行引擎不支持和DataSet转换

3. 将表转换成DataStream

	流式查询的结果Table会被动态的更新，即每个新的记录到达输入流时结果就会发生变化，因此，转换此动态查询的DataStream需要对表的更新进行编码
    - Append Mode：这种模式只适用于当动态表仅由INERT这种操作进行修改时，之前添加的数据不会被更新
    - Retract Mode：可以使用使用此模式，它使用一个Boolean标识来编码INSERT和DELETE操作

4. 将表转换成DataSet

## 5 Flink高级特性

### 5.1 Window（窗口）简介

- Window是一种可以把无界数据切割为有界数据块的手段
- 应用场景：计算过去5分钟；最后100个元素的和
- Window可以是时间驱动（Time Window），或者是数据驱动（Count Window）
- 可以分为滚动窗口（tumbling window）没有重叠、滑动窗口（sliding window）有重叠

Window使用：

- `timeWindow(Time.seconds(10))`：表示滚动窗口的窗口大小为10秒，对每10秒内的数据进行聚合计算
- `timeWindow(Time.seconds(10),Time.seconds(5))`：表示滑动窗口的窗口大小为10秒，滑动间隔为5秒，就是每隔5秒计算前10秒内的数据
- `countWindow(5)`：表示滚动窗口的大小是5个元素，也就是当窗口中填满5个元素的时候，就会对窗口进行计算了
- `countWindow(5,1)`：表示滑动窗口的窗口大小是5个元素，滑动的间隔为1个元素，也就是说每新增1个元素就会对前面5个元素计算一次
- 基于key的Window：使用`.keyBy().window()`方法
- 不基于key的Window：使用`.windowAll()`方法

### 5.2 Window聚合

1. 增量聚合
    - 窗口中每进入一条数据，就进行一次计算
    - 函数：reduce()、aggregate()、sum()、min()、max()

2. 全量聚合
	- 窗口的数据都到齐了，才开始进行聚合计算
	- 函数：apply(windowFunction)、process(processWindowFunction)

### 5.3 Time

- Event Time：事件产生的事件，通常由事件中的时间戳描述
- Ingestion Time：事件进入Flink的时间
- Processing Time（Flink默认）：事件被处理时的当前系统时间

### 5.3 Watermark

Window的触发机制：
- 先按照自然时间将window划分，如果window是3s，那么1min内会将Window划分为左闭右开的区间；
- 输入的数据根据自身的EventTime，将数据划分到不同的Window中；
- 如果Window中有数据，则当Watermark时间 >= EventTime时，符合Window触发条件；
- 最终决定Window触发，是由数据本身的EventTime所属Window中的window_end_time决定。

延迟数据的处理方式：
- 丢弃：由于数据所在窗口已经执行郭了，Flink默认对这些迟到的数据采取丢弃
- allowedLateness：指定允许数据延迟的时间
- sideOutputLateData：收集迟到的数据

多并行度的Watermark机制：Watermark对齐机制会获取所有Channel最小的Watermark

如何设置最大乱序时间：
- 结合业务以及数据情况设置：如果OutOfOrderness设置太小，而自身数据发送时由于网络等原因导致乱序或者迟到太多，可能会有很多数据被丢弃，对数据的正确性影响太大。
- 对于严重乱序的数据，需要严格统计数据最大延迟时间，保证计算数据的准确性，延迟时间设置太小会影响数据准确性，延迟时间设置太大不仅会影响数据的实时性，更会加重Flink作业的负担，尽量不要采用EventTime方式处理。

### 5.4 并行度

- 并行度的定义：一个Flink任务由多个组件组成（DataSource、Transformation和DataSink），一个组件由多个并行的实例（线程）来执行，一个组件的并行实例个数称为该组件的并行度。
- Slot数量=每个TaskManager节点的可用CPU数量
- 并行度设置：Operator Level（算子层面）、Execution Environment Level（执行环境层面）、Client Level（客户端层面）、System Level（系统层面）

###  5.5 Kafka Consumer容错

- 当Checkpoint机制开启时，Consumer会定期将Kafka的offset信息以及其他算子任务的State信息保存起来
- 当Job失败重启时，Flink会从最近一次的Checkpoint中进行恢复数据，重新消费Kafa中的数据
- 为了使用支持容错的Comsumer，需要开启Checkpoint，设置Checkpoint周期`env.enableCheckpointing(5000)`
- 执行Checkpoint时，数据保存方式：
	- MemoryStateBackend：State数据保存在JobManager内存中，在生产环境下面不建议使用
	- FsStateBackend：State快照数据保存到配置的文件系统中
	- RocksDBStateBackend：State数据保存到本地的RocksDB中，需要配置一个远端的文件系统，克服了State受内存限制的缺点，能够持久化到远端文件系统中，推荐在生产环境下使用

### 5.6 Kafka Producer容错

- 如果Flink开启了Checkpoint，针对FlinkKafka Producer可以提供EXACTLY_ONCE的语义保证
- 通过semantic参数指定三种不同的语义：Semantic.NONE、Semantic.AT_LEAST_ONCE（默认）、Semantic.EXACTLY_ONCE

- 由生产者中配置的超时时间（默认1小时）大于Kafka Broker设置事务的超时时间（默认15分钟），导致无法执行命令`nc -l 9001`，需要修改Kafka Broker的`transaction.max.timeout.ms`

修改Kafka的config目录下的`server.properties`文件内容：
```properties
transaction.max.timeout.ms=3600000
```

## 6 Spark Streaming

- Spark Steaming是Spark Core API的一种扩展，用于进行大规模、高吞吐量、容错的实时（近实时）数据流处理
