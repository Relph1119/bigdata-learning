# 第13章 Doris

## 1 Doris简介

Doris是由百度自研并开源的OLAP数据库，支持标准的SQL并完全兼容MySQL协议，仅需亚秒级响应时间即可返回海量数据下的查询结果。

### 1.1 特点

- 极简架构：融合了Google Mesa的数据存储模型、Apache的ORCFile存储格式、Apache Impala的查询引擎和MySQL交互协议。
- 使用简单：
    - 数据建模方面：支持Aggregate、Unique和Duplicate模型。
    - 数据导入方面：多种数据导入方案，在数据导入过程中保证原子操作。
    - SQL应用方面：支持标准的SQL语言，与MySQL兼容。
    - 工具方面：支持用户无缝使用DBeaver、DataGrip、Navicat等主流开发工具。
    - 集群可靠性方面：使用内存存储+检查点+镜像日志文件模式，使用BTBJE协议实现元数据的高可用和高可靠。
    - 集群扩缩容方面：基于分布式管理框架，自动管理数据副本的分布、修复和均衡。
    - 集群升级方面：只需要替换二进制程序，滚动重启集群即可。
- 功能丰富：
    - 分区分桶裁剪功能：第一层是分区，支持Range和List的划分方式；第二层是分桶，将数据通过Hash值进行水平划分，数据分片（Tablet）在集群中被均匀打散。
    - Bitmap数据类型：利用位图存储整型数据，进行集合操作。
    - 物化视图：满足用户对原始明细数据任意维度分析，快速对固定维度进行分析、查询。
- 开源开放：支持Apache License 2.0协议。
  
### 1.2 核心设计

- 存储引擎：
    - 针对不同的数据类型，提供不同的编码方式。
    - 支持最大空间为256MB的Segment，按列存储数据，每一列分为多个Page。
    - 提供两种索引：智能索引、二级索引
- 查询引擎：
    - 基于MPP框架的火山模型：基于SQL语句生成逻辑执行计划，根据数据分布，形成物理执行计划。
    - Agg阶段：重分布数据、汇总数据
- 查询优化器：基于规则和基于代价的查询优化，优化改进方面为常量折叠、子查询改写、提取公共表达式、智能预过滤、谓词下推。
- 向量化执行引擎：高效的向量数据结构（Vector） + 批量化处理数据（nextBatch） + Batch内性能优化（SIMD）

### 1.3 应用场景

- 实时大屏：对接Kafka和Flink，实现实时数据查询
- 固定报表：基于明细数据或者轻度汇总数据直接进行查询，通过MySQL交互协议支持各种报表工具。
- 自助分析：也称为多维分析，IT人员根据业务需求预先加工好维度数据和事实数据，供业务人员按照自由组合维度进行数据分析。提供丰富的Join操作和高效的Join查询，基于行列混合存储数据，仅需读取部分列进行计算。
- 用户画像：支持Bitmap去重，更优雅、快速地筛选用户。
- 多源联邦查询：通过Multi-Catalog功能，快速接入多种数据源。
- 实时数据仓库：利用Canal解析MySQL的binlog日志，利用Flume采集Web日志，最终写入Kafka并进行削峰填谷，提供稳定的数据流。Kafka数据直接通过Routine Load进入Doris，也可以经由Flink加工处理后写入Doris，通过视图或物化视图进行数据处理，由前端应用直接查询实时数据。

## 2 Doris部署

### 2.1 下载软件包

访问[Doris官网](https://doris.apache.org/download/)，下载最新的软件包`apache-doris-1.2.7-bin-x64.tar.xz`，在`/data/soft`目录下解压：
```shell
cd /data/soft
tar -xvf apache-doris-1.2.7-bin-x64.tar.xz
```

### 2.2 配置FE

1. 创建元数据目录
```shell
mkdir -p /data/doris/doris-meta
```

2. 修改`fe.conf`配置文件

在`/data/soft/apache-doris-1.2.7-bin-x64/fe/conf/fe.conf`文件中添加以下内容：
```properties
priority_networks=192.168.56.0/24
meta_dir=/data/doris/doris-meta
```

其中`priority_networks`表示FE的节点地址，`meta_dir`表示元数据目录。

### 2.3 启动FE

1. 启动FE

```shell
cd /data/soft/apache-doris-1.2.7-bin-x64/fe
./bin/start_fe.sh --daemon
```

2. 访问元数据管理页面

页面地址：http://192.168.56.101:8030/，使用`root`用户登录，密码为空。

3. 使用DataGrip连接数据库，配置MySQL连接

连接信息如下：
```text
host: 192.168.56.101
port: 9030
User: root
```

4. 验证FE是否启动正常

```genericsql
show frontends
```

如看到`Alive`为`true`，则FE节点启动正常。

### 2.3 配置BE

1. 创建数据存储目录

```shell
mkdir -p /data/doris/storage
```

2. 修改`be.conf`配置文件

在`/data/soft/apache-doris-1.2.7-bin-x64/be/conf/be.conf`文件中添加以下内容：
```properties
priority_networks=192.168.56.0/24
storage_root_path=/data/doris/storage
JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64
```

其中`priority_networks`表示BE的节点地址，`storage_root_path`表示数据存储目录。

3. 修改系统参数

```shell
sysctl -w vm.max_map_count=2000000
ulimit -n 65536
```

### 2.4 启动BE

1. 启动BE

```shell
cd /data/soft/apache-doris-1.2.7-bin-x64/be
./bin/start_be.sh --daemon
```

2. 添加BE节点到集群

在MySQL查询窗口中，执行以下代码：
```genericsql
alter system add backend "192.168.56.101:9050";
```

3. 验证BE是否启动正常

```genericsql
show backends
```

如看到`Alive`为`true`，则BE节点启动正常。

### 2.5 修改默认用户`root`的密码

在MySQL查询窗口中，执行以下代码设置密码为root：
```genericsql
set password for 'root'=password('root')
```

## 3 Doris数据对象

### 3.1 数据类型

- 数值类型：TINTINT、SMALLINT、INT、BIGINT、LARGEINT、FLOAT、DOUBLE、DECIMAL
- 日期时间类型：DATE、DATETIME
- 字符串类型：CHAR、VARCHAR、TEXT
- BITMAP类型：只能用于`Aggregate`数据模型的表，不能用在`Key`列，建表时需搭配`BITMAP_UNION`使用。
- HLL类型：只能用于`Aggregate`数据模型的表，不能用在`Key`列，建表时需搭配`HLL_UNION`使用。
- BOOLEAN类型：建议用`CHAR(1)`或`VARCHAR(1)`代替

### 3.2 外部表引擎

- MySQL表引擎
- Broker表引擎：用于读取外部数据文件映射成Doris数据库的外部表，支持读取HDFS、S3、BOS等存储系统上的文件。文件名中的逗号用`%2c`代替，`%`用`%25`代替。
- Hive表引擎
- Iceberg表引擎

### 3.3 函数

- 日期函数：TIME_ROUND
- 正则匹配函数：REGEXP（正向匹配）、REGEXP_EXTRACT（提取）、REGEXP_REPLACE（替换）、NOT REGEXP（反向匹配）
- BITMAP函数：BITMAP_EMPTY、BITMAP_HASH、BITMAP_UNION
- JSON函数：get_json_double()、get_json_int()、get_json_string()
- 表函数：将一条记录转换成多条记录，包括EXPLODE_BITMAP、EXPLODE_SPLIT、EXPLODE_JSON_ARRAY、
- 窗口函数：每个窗口内的数据可以用OVER从句进行排序和分组。

## 4 Doris数据模型

### 4.1 数据聚合过程

Aggregate模型和Unique模型的数据聚合过程：

1. 数据写入阶段：针对每一个批次的导入数据，先在批次内进行数据合并。
2. 节点数据压实阶段：在数据写入后，BE节点不定期进行跨批次的数据合并。
3. 数据查询阶段：对于涉及查询的数据，会进行进一步聚合，避免返回错误的结果。

### 4.2 数据模型应用场景

- Aggregate模型：适合有固定模式的报表类查询场景。
- Unique模型：针对需要唯一主键约束的场景，适合数仓的ODS层。
- Duplicate模型：适合任意维度的Ad-hoc查询。

### 4.3 ORCFile

**存储格式：**

- Index Data：存储某Stripe上数据的位置、总行数等信息。
- Row Data：以Stream的形式存储数据信息。
- Stripe Footer：存储某Stripe的统计结果，包括Max、Min、count等信息。
- File Footer：存储表的统计结果，以及各Stripe的位置信息。
- Postscript：存储表的行数、压缩参数、压缩大小、列等信息。

**优点：**

- 数据切块：按照分区数+数据块切分
- 压缩策略：块内按照列存储方式压缩
- 字典压缩：支持
- 数据压缩比：压缩比一般为7:1左右
- 数据写入：适合批量写入
- 数据读取：整行读取和部分字段读取效率都比较高
- 数据更新：支持按照索引更新
- 数据删除：支持按照索引删除
- 索引：效果非常好

### 4.4 分区分桶原则

- Tablet数量原则：在不考虑扩容的情况下，一个表的Tablet数量略多于整个集群的磁盘数量。
- Tablet数据量原则（优先）：单个Tablet的数据量大小设置在1G\~10G内，单个Tablet数据量过小，数据聚合效果不佳，元数据管理压力大；如果数据量过大，不利于副本的迁移、补齐，会提高Schema变更或者Rollup操作失败的概率。

### 4.5 DDL语句执行过程

1. 用户发起DDL语句执行请求，提交给FE节点。
2. 识别命令类型：FE启动事件监听器来监听用户的连接，命令类型包括初始化数据连接、端口连接、SQL语句执行。
3. 词法和语法解析：词法解析是判断单词的正确性，语法解析是判断多个单词组合在一个是否为一个合法的操作命令。
4. DDL语句执行
5. 元数据修改：修改Catalog数据和通知BE节点创建对应的文件夹。
6. 元数据持久化：把修改信息持久化到日志文件中，以便数据库重启后可以通过回放恢复对应的元数据。

## 5 数据导入

- Stream Load方式：同步导入方式，允许用户通过HTTP将CSV格式或者JSON格式的数据批量导入，并返回数据导入结果。
- Broker Load方式：异步导入方式，读取对应数据源（如HDFS、S3）中的数据，对数据进行预处理和导入。
- Routine Load方式：例行导入方式，从Kafka持续导入数据。
- Binlog Load方式：支持对接Canal，从Canal Server上获取MySQL的Binlog数据并解析，再导入Doris。
- Spark Load方式：异步导入方式，通过外部的Spark资源实现对导入数据的预处理。

### 5.1 Stream Load执行流程

1. 用户提交`Stream Load`请求到节点（`FE`或`BE`）。
2. 接收到请求后，进行`Header`解析（解析数据导入的库、表、`Label`等信息），进行用户鉴权，`FE`节点将`Stream Load`请求转发到一个`BE`节点，`BE`节点作为本次任务的协调者（Coordinator）。
3. `Coordinator BE`进行`Header`解析（解析数据的文件格式、消息体的大小、超时时间、用户鉴权信息等），数据校验。
4. `Coordinator BE`通过`Thrift RPC`向`FE`节点发送`Begin Transaction`请求。
5. `FE`节点开启一个事务，并向`Coordinator BE`返回事务ID。
6. `Coordinator BE`收到事务ID，通过`Thrift RPC`向`FE`节点发送获取导入计划的请求。
7. `FE`节点为任务生成导入计划，返回给`Coordinator BE`。
8. `Coordinator BE`执行导入计划，将接收传来的实时数据通过`BRPC`分发给其他`Executor BE`。
9. 其他`Executor BE`将数据写入存储层。
10. `Coordinator BE`通过`Thrift RPC`向`FE`节点发送`Commit Transaction`请求。
11. `FE`节点对事务进行提交，向`Executor BE`发送`Publish Version`任务，等待执行完成。
12. `Executor BE`异步执行，将数据导入时生成的`Rowset`变为可见数据版本。
13. 当`Publish Version`任务正常完成，`FE`向`Coordinator BE`返回`Commit Transaction`和`Publish Version`任务结果。
14. `Coordinator BE`向用户返回`Stream Load`执行的最终结果。

### 5.2 Broker Load执行流程

1. 用户创建`Broker Loader`任务，提交给`FE`。
2. `FE`根据文件存储大小和文件个数，制定数据分片导入计划。
3. `FE`按照计划指挥多个`BE`节点导入指定的文件或分片数据。
4. `BE`通过`Broker`拉取数据，写入磁盘。
5. `BE`完成数据导入后，反馈消息给`FE`。
6. `FE`继续下发任务给`BE`，直到所有文件数据都导入完成。
7. `FE`收到所有文件数据导入完成的消息后，反馈给用户。

### 5.3 Routine Load执行流程

1. 用户通过支持MySQL协议的客户端向`FE`提交`Routine Load`任务。
2. `FE`通过`JobScheduler`将导入任务拆分成若干个`Task`，每个`Task`负责导入指定的一部分数据。
3. 每个`Task`被`TaskScheduler`分配到指定的`BE`上执行。
4. `BE`导入任务完成后，向`FE`汇报。
5. `FE`中的`JobScheduler`根据汇报结果，继续生成新的`Task`，或者对失败的`Task`进行重试。
6. `FE`不断产生新的`Task`，完成数据不间断导入任务。

### 5.4 Binlog Load执行流程

1. 用户向`FE`提交数据同步作业。
2. `FE`为每个数据同步作业启动一个`Canal Client`，向`Canal Server`端订阅并获取数据。
3. `Canal Client`中的`Receiver`负责通过`Get`命令接收数据，每获取到一个数据`Batch`，由`Consumer`根据对应表分发到不同的`Channel`，每个`Channel`产生一个发送数据的子任务`Task`。在`FE`上，一个`Task`包含分发到当前`Channel`的同一个`Batch`的数据。
4. 一个事务周期内，一般会从`Consumer`获取到多个`Batch`的数据，产生多个向`BE`发送数据的子任务`Task`。
5. 如果满足一定条件（超时、达到提交最大数据大小），`Consumer`会阻塞并通知各个`Channel`提交事务。
6. 当所有`Channel`都提交成功，`Canal Client`通过`Ack`命令通知`Canal Server`继续获取并消费数据。
7. 如果有任意`Channel`提交失败，将会重新从上一次消费成功的位置获取数据并再次提交。
8. 整个数据同步作业中，`FE`通过以上流程不断从`Canal`获取数据，并提交到`BE`。
9. 数据由`Coordinator BE`接收，并分发给对应的`BE`存储。

### 5.5 Spark Load执行流程

1. 用户创建`Spark Load`任务。
2. `FE`调度并提交`ETL`任务到`Spark`集群执行。
3. `Spark`集群执行`ETL`任务，完成对导入数据的预处理，包括全局字典构建、分区、排序、聚合等。
4. `ETL`任务完成后，`FE`获取预处理后的每个分片的数据路径，并调度相关的`BE`推送任务。
5. `BE`通过`Broker`读取数据，并将数据格式转换为Doris存储格式。
6. `FE`调度将最新导入的数据设置为有效版本，完成导入任务。

## 6 数据查询

### 6.1 JOIN算法实现

- 循环嵌套连接：用于查询的选择性强、约束性强，并且仅返回小部分记录的结果集。适合大表连接小表的场景。
- 归并连接：也称排序合并连接，适合非等值连接的场景。
- 哈希连接：分为两个阶段，分别是构建阶段、探测阶段。适合两个大表的多个字段关联场景。

### 6.2 JOIN策略

- Shuffle Join：将两张表中的数据按照关联字段的哈希值打散，Key值相同的数据分配到同一个节点，按照Join算法进行数据关联。
- Bucket Shuffle Join：当两张表拥有相同的分布字段，数据量较小的一张表按照大表的分布键进行数据重分布。
- Broadcast Join：将小表数据复制到所有大表有数据的节点，用大表的部分数据关联小表的全部数据。
- Colocate Join：也称Local Join，多个表关联时没有数据移动和网络传输，每个节点只在本地进行数据关联，将关联结果返回汇总节点。

## 7 Doris查询优化

### 7.1 索引

- 前缀索引：在排序的基础上根据给定前缀列，快速查询数据的索引方式，以Block为粒度创建的稀疏索引，一个Block包含1024行数据，第一行数据的前缀列的值为索引。
- Bloom Filter索引：是一种位图结构，用于快速判断一个给定的值是否在一个集合中，以Block为粒度创建的，每个Block中指定列的值作为一个集合，生成一个BF索引条目。
- BITMAP索引：使用bit数组进行数据存储，位置编码中的每一个位表示键值对应的数据行的有无。

### 7.2 ROLLUP

- ROLLUP最根本的作用是提高某些查询的效率。
- ROLLUP表附属于Base表。
- ROLLUP表中的数据是独立存储的。
- ROLLUP表中的数据更新与Base表中的数据更新完全同步。
- ROLLUP表中列的聚合方式与Base表中的完全相同。
- 查询引擎能否命中ROLLUP表的一个必要条件是，查询所涉及的所有列都存在于该ROLLUP表的列中。
- 某些类型的查询，在任何条件下，都无法命中ROLLUP表。
- 可以通过`EXPLAIN your_sql`命令获得查询执行计划，查看是否命中ROLLUP表。

