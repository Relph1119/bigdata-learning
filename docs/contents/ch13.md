# 第13章 Doris

## 1 Doris简介

Doris是由百度自研并开源的OLAP数据库，支持标准的SQL并完全兼容MySQL协议，仅需亚秒级响应时间即可返回海量数据下的查询结果。

### 1.1 特点

- 极简架构：融合了Google Mesa的数据存储模型、Apache的ORCFile存储格式、Apache Impala的查询引擎和MySQL交互协议。
- 使用简单：
    - 数据建模方面：支持Aggregate、Unique和Duplicate模型。
    - 数据导入方面：多种数据导入方案，在数据导入过程中保证原子操作。
    - SQL应用方面：支持标准的SQL语言，与MySQL兼容。
    - 工具方面：支持用户无缝使用DBeaver、DataGrip、Navicat等主流开发工具。
    - 集群可靠性方面：使用内存存储+检查点+镜像日志文件模式，使用BTBJE协议实现元数据的高可用和高可靠。
    - 集群扩缩容方面：基于分布式管理框架，自动管理数据副本的分布、修复和均衡。
    - 集群升级方面：只需要替换二进制程序，滚动重启集群即可。
- 功能丰富：
    - 分区分桶裁剪功能：第一层是分区，支持Range和List的划分方式；第二层是分桶，将数据通过Hash值进行水平划分，数据分片（Tablet）在集群中被均匀打散。
    - Bitmap数据类型：利用位图存储整型数据，进行集合操作。
    - 物化视图：满足用户对原始明细数据任意维度分析，快速对固定维度进行分析、查询。
- 开源开放：支持Apache License 2.0协议。
  
### 1.2 核心设计

- 存储引擎：
    - 针对不同的数据类型，提供不同的编码方式。
    - 支持最大空间为256MB的Segment，按列存储数据，每一列分为多个Page。
    - 提供两种索引：智能索引、二级索引
- 查询引擎：
    - 基于MPP框架的火山模型：基于SQL语句生成逻辑执行计划，根据数据分布，形成物理执行计划。
    - Agg阶段：重分布数据、汇总数据
- 查询优化器：基于规则和基于代价的查询优化，优化改进方面为常量折叠、子查询改写、提取公共表达式、智能预过滤、谓词下推。
- 向量化执行引擎：高效的向量数据结构（Vector） + 批量化处理数据（nextBatch） + Batch内性能优化（SIMD）

### 1.3 应用场景

- 实时大屏：对接Kafka和Flink，实现实时数据查询
- 固定报表：基于明细数据或者轻度汇总数据直接进行查询，通过MySQL交互协议支持各种报表工具。
- 自助分析：也称为多维分析，IT人员根据业务需求预先加工好维度数据和事实数据，供业务人员按照自由组合维度进行数据分析。提供丰富的Join操作和高效的Join查询，基于行列混合存储数据，仅需读取部分列进行计算。
- 用户画像：支持Bitmap去重，更优雅、快速地筛选用户。
- 多源联邦查询：通过Multi-Catalog功能，快速接入多种数据源。
- 实时数据仓库：利用Canal解析MySQL的binlog日志，利用Flume采集Web日志，最终写入Kafka并进行削峰填谷，提供稳定的数据流。Kafka数据直接通过Routine Load进入Doris，也可以经由Flink加工处理后写入Doris，通过视图或物化视图进行数据处理，由前端应用直接查询实时数据。

## 2 Doris部署

### 2.1 下载软件包

访问[Doris官网](https://doris.apache.org/download/)，下载最新的软件包`apache-doris-1.2.7-bin-x64.tar.xz`，在`/data/soft`目录下解压：
```shell
cd /data/soft
tar -xvf apache-doris-1.2.7-bin-x64.tar.xz
```

### 2.2 配置FE

1. 创建元数据目录
```shell
mkdir -p /data/doris/doris-meta
```

2. 修改`fe.conf`配置文件

在`/data/soft/apache-doris-1.2.7-bin-x64/fe/conf/fe.conf`文件中添加以下内容：
```properties
priority_networks=192.168.56.0/24
meta_dir=/data/doris/doris-meta
```

其中`priority_networks`表示FE的节点地址，`meta_dir`表示元数据目录。

### 2.3 启动FE

1. 启动FE

```shell
cd /data/soft/apache-doris-1.2.7-bin-x64/fe
./bin/start_fe.sh --daemon
```

2. 访问元数据管理页面

页面地址：http://192.168.56.101:8030/，使用`root`用户登录，密码为空。

3. 使用DataGrip连接数据库，配置MySQL连接

连接信息如下：
```text
host: 192.168.56.101
port: 9030
User: root
```

4. 验证FE是否启动正常

```genericsql
show frontends
```

如看到`Alive`为`true`，则FE节点启动正常。

### 2.3 配置BE

1. 创建数据存储目录

```shell
mkdir -p /data/doris/storage
```

2. 修改`be.conf`配置文件

在`/data/soft/apache-doris-1.2.7-bin-x64/be/conf/be.conf`文件中添加以下内容：
```properties
priority_networks=192.168.56.0/24
storage_root_path=/data/doris/storage
JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64
```

其中`priority_networks`表示BE的节点地址，`storage_root_path`表示数据存储目录。

3. 修改系统参数

```shell
sysctl -w vm.max_map_count=2000000
ulimit -n 65536
```

### 2.4 启动BE

1. 启动BE

```shell
cd /data/soft/apache-doris-1.2.7-bin-x64/be
./bin/start_be.sh --daemon
```

2. 添加BE节点到集群

在MySQL查询窗口中，执行以下代码：
```genericsql
alter system add backend "192.168.56.101:9050";
```

3. 验证BE是否启动正常

```genericsql
show backends
```

如看到`Alive`为`true`，则BE节点启动正常。

### 2.5 修改默认用户`root`的密码

在MySQL查询窗口中，执行以下代码设置密码为root：
```genericsql
set password for 'root'=password('root')
```

## 3 Doris数据对象

### 3.1 数据类型

- 数值类型：TINTINT、SMALLINT、INT、BIGINT、LARGEINT、FLOAT、DOUBLE、DECIMAL
- 日期时间类型：DATE、DATETIME
- 字符串类型：CHAR、VARCHAR、TEXT
- BITMAP类型：只能用于`Aggregate`数据模型的表，不能用在`Key`列，建表时需搭配`BITMAP_UNION`使用。
- HLL类型：只能用于`Aggregate`数据模型的表，不能用在`Key`列，建表时需搭配`HLL_UNION`使用。
- BOOLEAN类型：建议用`CHAR(1)`或`VARCHAR(1)`代替

### 3.2 外部表引擎

- MySQL表引擎
- Broker表引擎：用于读取外部数据文件映射成Doris数据库的外部表，支持读取HDFS、S3、BOS等存储系统上的文件。文件名中的逗号用`%2c`代替，`%`用`%25`代替。
- Hive表引擎
- Iceberg表引擎

### 3.3 函数

- 日期函数：TIME_ROUND
- 正则匹配函数：REGEXP（正向匹配）、REGEXP_EXTRACT（提取）、REGEXP_REPLACE（替换）、NOT REGEXP（反向匹配）
- BITMAP函数：BITMAP_EMPTY、BITMAP_HASH、BITMAP_UNION
- JSON函数：get_json_double()、get_json_int()、get_json_string()
- 表函数：将一条记录转换成多条记录，包括EXPLODE_BITMAP、EXPLODE_SPLIT、EXPLODE_JSON_ARRAY、
- 窗口函数：每个窗口内的数据可以用OVER从句进行排序和分组。

## 4 Doris数据模型

### 4.1 数据聚合过程

Aggregate模型和Unique模型的数据聚合过程：

1. 数据写入阶段：针对每一个批次的导入数据，先在批次内进行数据合并。
2. 节点数据压实阶段：在数据写入后，BE节点不定期进行跨批次的数据合并。
3. 数据查询阶段：对于涉及查询的数据，会进行进一步聚合，避免返回错误的结果。

### 4.2 数据模型应用场景

- Aggregate模型：适合有固定模式的报表类查询场景。
- Unique模型：针对需要唯一主键约束的场景，适合数仓的ODS层。
- Duplicate模型：适合任意维度的Ad-hoc查询。

### 4.3 ORCFile

**存储格式：**

- Index Data：存储某Stripe上数据的位置、总行数等信息。
- Row Data：以Stream的形式存储数据信息。
- Stripe Footer：存储某Stripe的统计结果，包括Max、Min、count等信息。
- File Footer：存储表的统计结果，以及各Stripe的位置信息。
- Postscript：存储表的行数、压缩参数、压缩大小、列等信息。

**优点：**

- 数据切块：按照分区数+数据块切分
- 压缩策略：块内按照列存储方式压缩
- 字典压缩：支持
- 数据压缩比：压缩比一般为7:1左右
- 数据写入：适合批量写入
- 数据读取：整行读取和部分字段读取效率都比较高
- 数据更新：支持按照索引更新
- 数据删除：支持按照索引删除
- 索引：效果非常好

### 4.4 分区分桶原则

- Tablet数量原则：在不考虑扩容的情况下，一个表的Tablet数量略多于整个集群的磁盘数量。
- Tablet数据量原则（优先）：单个Tablet的数据量大小设置在1G\~10G内，单个Tablet数据量过小，数据聚合效果不佳，元数据管理压力大；如果数据量过大，不利于副本的迁移、补齐，会提高Schema变更或者Rollup操作失败的概率。

### 4.5 DDL语句执行过程

1. 用户发起DDL语句执行请求，提交给FE节点。
2. 识别命令类型：FE启动事件监听器来监听用户的连接，命令类型包括初始化数据连接、端口连接、SQL语句执行。
3. 词法和语法解析：词法解析是判断单词的正确性，语法解析是判断多个单词组合在一个是否为一个合法的操作命令。
4. DDL语句执行
5. 元数据修改：修改Catalog数据和通知BE节点创建对应的文件夹。
6. 元数据持久化：把修改信息持久化到日志文件中，以便数据库重启后可以通过回放恢复对应的元数据。

## 5 数据导入

- Stream Load方式：同步导入方式，允许用户通过HTTP将CSV格式或者JSON格式的数据批量导入，并返回数据导入结果。
- Broker Load方式：异步导入方式，读取对应数据源（如HDFS、S3）中的数据，对数据进行预处理和导入。
- Routine Load方式：例行导入方式，从Kafka持续导入数据。
- Binlog Load方式：支持对接Canal，从Canal Server上获取MySQL的Binlog数据并解析，再导入Doris。
- Spark Load方式：异步导入方式，通过外部的Spark资源实现对导入数据的预处理。

### 5.1 Stream Load执行流程

1. 用户提交`Stream Load`请求到节点（`FE`或`BE`）。
2. 接收到请求后，进行`Header`解析（解析数据导入的库、表、`Label`等信息），进行用户鉴权，`FE`节点将`Stream Load`请求转发到一个`BE`节点，`BE`节点作为本次任务的协调者（Coordinator）。
3. `Coordinator BE`进行`Header`解析（解析数据的文件格式、消息体的大小、超时时间、用户鉴权信息等），数据校验。
4. `Coordinator BE`通过`Thrift RPC`向`FE`节点发送`Begin Transaction`请求。
5. `FE`节点开启一个事务，并向`Coordinator BE`返回事务ID。
6. `Coordinator BE`收到事务ID，通过`Thrift RPC`向`FE`节点发送获取导入计划的请求。
7. `FE`节点为任务生成导入计划，返回给`Coordinator BE`。
8. `Coordinator BE`执行导入计划，将接收传来的实时数据通过`BRPC`分发给其他`Executor BE`。
9. 其他`Executor BE`将数据写入存储层。
10. `Coordinator BE`通过`Thrift RPC`向`FE`节点发送`Commit Transaction`请求。
11. `FE`节点对事务进行提交，向`Executor BE`发送`Publish Version`任务，等待执行完成。
12. `Executor BE`异步执行，将数据导入时生成的`Rowset`变为可见数据版本。
13. 当`Publish Version`任务正常完成，`FE`向`Coordinator BE`返回`Commit Transaction`和`Publish Version`任务结果。
14. `Coordinator BE`向用户返回`Stream Load`执行的最终结果。

### 5.2 Broker Load执行流程

1. 用户创建`Broker Loader`任务，提交给`FE`。
2. `FE`根据文件存储大小和文件个数，制定数据分片导入计划。
3. `FE`按照计划指挥多个`BE`节点导入指定的文件或分片数据。
4. `BE`通过`Broker`拉取数据，写入磁盘。
5. `BE`完成数据导入后，反馈消息给`FE`。
6. `FE`继续下发任务给`BE`，直到所有文件数据都导入完成。
7. `FE`收到所有文件数据导入完成的消息后，反馈给用户。

### 5.3 Routine Load执行流程

1. 用户通过支持MySQL协议的客户端向`FE`提交`Routine Load`任务。
2. `FE`通过`JobScheduler`将导入任务拆分成若干个`Task`，每个`Task`负责导入指定的一部分数据。
3. 每个`Task`被`TaskScheduler`分配到指定的`BE`上执行。
4. `BE`导入任务完成后，向`FE`汇报。
5. `FE`中的`JobScheduler`根据汇报结果，继续生成新的`Task`，或者对失败的`Task`进行重试。
6. `FE`不断产生新的`Task`，完成数据不间断导入任务。

### 5.4 Binlog Load执行流程

1. 用户向`FE`提交数据同步作业。
2. `FE`为每个数据同步作业启动一个`Canal Client`，向`Canal Server`端订阅并获取数据。
3. `Canal Client`中的`Receiver`负责通过`Get`命令接收数据，每获取到一个数据`Batch`，由`Consumer`根据对应表分发到不同的`Channel`，每个`Channel`产生一个发送数据的子任务`Task`。在`FE`上，一个`Task`包含分发到当前`Channel`的同一个`Batch`的数据。
4. 一个事务周期内，一般会从`Consumer`获取到多个`Batch`的数据，产生多个向`BE`发送数据的子任务`Task`。
5. 如果满足一定条件（超时、达到提交最大数据大小），`Consumer`会阻塞并通知各个`Channel`提交事务。
6. 当所有`Channel`都提交成功，`Canal Client`通过`Ack`命令通知`Canal Server`继续获取并消费数据。
7. 如果有任意`Channel`提交失败，将会重新从上一次消费成功的位置获取数据并再次提交。
8. 整个数据同步作业中，`FE`通过以上流程不断从`Canal`获取数据，并提交到`BE`。
9. 数据由`Coordinator BE`接收，并分发给对应的`BE`存储。

### 5.5 Spark Load执行流程

1. 用户创建`Spark Load`任务。
2. `FE`调度并提交`ETL`任务到`Spark`集群执行。
3. `Spark`集群执行`ETL`任务，完成对导入数据的预处理，包括全局字典构建、分区、排序、聚合等。
4. `ETL`任务完成后，`FE`获取预处理后的每个分片的数据路径，并调度相关的`BE`推送任务。
5. `BE`通过`Broker`读取数据，并将数据格式转换为Doris存储格式。
6. `FE`调度将最新导入的数据设置为有效版本，完成导入任务。

## 6 数据查询

### 6.1 JOIN算法实现

- 循环嵌套连接：用于查询的选择性强、约束性强，并且仅返回小部分记录的结果集。适合大表连接小表的场景。
- 归并连接：也称排序合并连接，适合非等值连接的场景。
- 哈希连接：分为两个阶段，分别是构建阶段、探测阶段。适合两个大表的多个字段关联场景。

### 6.2 JOIN策略

- Shuffle Join：将两张表中的数据按照关联字段的哈希值打散，Key值相同的数据分配到同一个节点，按照Join算法进行数据关联。
- Bucket Shuffle Join：当两张表拥有相同的分布字段，数据量较小的一张表按照大表的分布键进行数据重分布。
- Broadcast Join：将小表数据复制到所有大表有数据的节点，用大表的部分数据关联小表的全部数据。
- Colocate Join：也称Local Join，多个表关联时没有数据移动和网络传输，每个节点只在本地进行数据关联，将关联结果返回汇总节点。

## 7 Doris查询优化

### 7.1 索引

- 前缀索引：在排序的基础上根据给定前缀列，快速查询数据的索引方式，以Block为粒度创建的稀疏索引，一个Block包含1024行数据，第一行数据的前缀列的值为索引。
- Bloom Filter索引：是一种位图结构，用于快速判断一个给定的值是否在一个集合中，以Block为粒度创建的，每个Block中指定列的值作为一个集合，生成一个BF索引条目。
- BITMAP索引：使用bit数组进行数据存储，位置编码中的每一个位表示键值对应的数据行的有无。

### 7.2 ROLLUP

- ROLLUP最根本的作用是提高某些查询的效率。
- ROLLUP表附属于Base表。
- ROLLUP表中的数据是独立存储的。
- ROLLUP表中的数据更新与Base表中的数据更新完全同步。
- ROLLUP表中列的聚合方式与Base表中的完全相同。
- 查询引擎能否命中ROLLUP表的一个必要条件是，查询所涉及的所有列都存在于该ROLLUP表的列中。
- 某些类型的查询，在任何条件下，都无法命中ROLLUP表。
- 可以通过`EXPLAIN your_sql`命令获得查询执行计划，查看是否命中ROLLUP表。

## 8 Fink Doris Connector

### 8.1 安装Fink Doris Connector

1. 访问[Flink Doris Connector的jar包库](https://repo.maven.apache.org/maven2/org/apache/doris/)， 下载jar包`flink-doris-connector-1.11_2.12-1.0.3.jar`，并存放到`/data/soft/flink-1.11.1/lib`目录下。

2. 访问[Maven仓库](https://search.maven.org/artifact/com.alibaba.ververica/flink-sql-connector-mysql-cdc/1.1.1/jar)， 下载jar包`flink-sql-connector-mysql-cdc-1.1.1.jar`，并存放到`/data/soft/flink-1.11.1/lib`目录下。

3. 启动Flink
```shell
cd /data/soft/flink-1.11.1/bin
./start-clushter.sh
```

4. 访问Flink Dashboard页面（http://192.168.56.101:8081/）

### 8.2 配置Doris

1. 在FE的配置中启动http v2

打开`fe.conf`文件：
```shell
cd /data/soft/apache-doris-1.2.7-bin-x64/fe
vim conf/fe.conf
```

启动http v2，添加如下配置：
```shell
enable_http_server_v2=true
```

2. 在BE的配置中开启Stream Load

打开`be.conf`文件：
```shell
cd /data/soft/apache-doris-1.2.7-bin-x64/be
vim conf/be.conf
```

开启Stream Load，添加如下配置：
```shell
disable_stream_load_2pc=false
```

## 9 系统管理

### 9.1 Doris版本升级

- 只需升级FE、BE、Broker进程，必须严格按照BE -> FE -> Broker顺序升级。
- 升级过程中会有节点重启情况，先关闭副本均很和副本修复逻辑：
  ```shell
  # 关闭普通表的副本均衡逻辑
  admin set frontend config("disable_balance"="true");
  # 针对特殊的Colocation表，执行以下命令关闭副本均衡
  admin set frontend config("disable_colocation_balance"="true")
  # 关闭副本调度逻辑，关闭后，所有已产生的副本修复和副本均衡任务不会再被调度
  admin set frontend config("disable_tablet_scheduler"="true")
  ```

### 9.2 集群缩扩容

- FE扩容：
  ```shell
  # 添加Follower
  alter system add follower "host:port"
  # 添加Observer
  alter system add observer "host:port"
  ```

- FE缩容：
  ```shell
  alter system drop follower[observer] "fe_host:edit_log_port"
  ```
  
- BE扩容：
  ```shell
  alter system add backend "host:port"
  ```
  
- BE缩容：
  ```shell
  alter system decommission backend "be_host:be_heartbeat_service_port"
  ```
  
- Broker扩缩容：

  ```shell
  # 扩容
  alter system add broker broker_name "broker_host:broker_ipc_port"
  # 缩容
  alter system drop broker broker_name "broker_host:broker_ipc_port"
  ```
  
## 10 基于Doris的OLAP查询和实时数据仓库实战（零售BI项目）

### 10.1 项目背景

- 业务背景：某头部运动品牌企业旗下的一个子品牌的零售BI项目，内容包含主数据梳理、零售业务分析和商品库存分析，交易系统已积累3年历史数据，包括2000万零售小票和6000万库存出入明细数据
- 业务痛点：
    1. 数据孤岛
    2. 手工制作报表耗时耗力
    3. 企业现有分析维度单一
    4. 未能体现历史数据的价值

### 10.2 项目需求

- 主要需求：抽取店铺的销售明细数据、店仓的进出库明细数据，搭建以店铺为中心的零售模型和以店仓为中心的库存模型。
- 零售模型：
    - 线下门店销售：从新零售系统抽取，用于计算店铺销售数量、销售金额、销售吊牌金额、折扣，围绕店铺的考核加工有效店、同店的标识，计算同店销售金额。
    - 线上门店销售：包括天猫、京东、唯品会、抖音等电商平台的销售，来源于新电商系统。
- 库存模型：
    - 大仓库存、门店库存：来自新零售系统，包括每日仓库进出明细、每月汇总的库存状态、仓库间调拨明细。
    - 电商库存：来自新电商系统，包括每日库存。
- 前端展示：
    - 移动端BI报表：包括总部零售看板、区域零售看板、门店零售看板、总部商品看板等。
    - PC端自助分析报表：零售多维自助分析报表、销存结构多维自助报表、售罄率多维自助分析报表等。
    - 实时销售报表：总部、区域、门店3个维度的当日实时销售数据分析报表。

### 10.3 技术方案实现

**技术架构**

- 展现层：移动BI、经营驾驶舱、自助分析
- 应用层+数据仓库：Doris实时数仓（T+0）、Hadoop/Hive+Spark+OLAP查询引擎Doris（T+1）
- 数据同步：Debezium+DataX、DolphinScheduler调度系统
- 数据源：新零售T+0实时数据、新零售T+1离线数据、新电商系统、门店数据、SAP采购调拨数据

**数据分层**

- ODS层：实现数据抽取流程标准化配置，简化操作。
- DIM层：主要围绕商品、网点两个主数据进行加工。
    - 商品：以SKC为核心，分析维度包括商品大类、商品中类、商品品类、销售年季、上市日期、上市批次、商品系列等。
    - 网点：有店铺和仓库组成，分析维度包括线上线下标识、店仓标识、门店的省市区位置、门店管理层级、经营方式、加盟形式、商圈、开关店日期等。
- DWD层：主要围绕商品销售明细和商品出入库明细开展。
    - 销售：构建以销售订单、店铺、商品编码为核心的销售明细模型
    - 库存：构建以调拨单号、店仓代码、商品SKU为核心的出入明细模型
    - 在途模型：抽取商品在调出和调入之间由于时间差产生的数据
- DWS层：在DWD层基础上汇总数据并根据业务逻辑计算指标
    - 销售明细模型加工的指标：销售吊牌价、同店销售明细、有效店销售明细等。
    - 出入库明细模型加工的指标：物理库存、在途库存、财务库存。
    - 两者结合的指标：售罄率、动销率、齐码率、库销比等。
- ADS层：区间销售统计、库存状态查询、出入库指标、售罄率指标、渠道分析指标、店铺销售排名

**技术实现**

- 基于Doris构建数据集市：通过Hive完成数据加工，通过Routine Load同步全量或增量数据。
- 基于Flink SQL的实时数据流：通过Debezium日志解析功能，读取数据库的CDC日志到Kafka，由Flink完成数据的清洗并关联离线批处理好的维度数据，写入Doris。

## 11 基于Doris的流批一体数据仓库实战（特步儿童业务BI分析项目）

### 11.1 项目背景

- 业务背景：特步儿童坚持中高档的商品定位，三四线城市的架构定位，专注于3\~14岁儿童群体，关注白领阶层父母对儿童商品的消费。为了实现特步业务增长和效率提升战略，通过准确、统一、快速的数据分析能力建设，持续提升数字化战略实现价值，实现精细化管理运营。
- 业务痛点：
    1. 企业经营过程中，各业务环节数据未打通，业务分析断层。
    2. 数据处理依赖手工，耗时长，工作量大。
    3. 缺乏数据洞察能力，数据展现不直观。

### 11.2 项目需求

- 主要需求：整合线上、线下数据，打通数据孤岛，提供全口径、准确、实时的数据分析结果。
- 项目范围：高管概览、零售、商品、会员、渠道、导购、节假日、故事包、直配店、店群管理、KPI看板等11个场景，主要包括商品和店铺等维度数据、线下全渠道销售数据、线上电商销售数据、库存商品变动数据和补录的考核目标数据。
- 涉及维度：时间、组织架构、产品、会员。
- 业务数据：全渠道DRP系统中的门店销售模型数据、门店商品调拨数据、会员消费数据，SPA系统中的商品调拨数据、批发数据、总仓和分公司仓库明细，多套电商平台中的商品销售数据，业务部门手动维护的目标数据等。

### 11.3 技术方案实现

**技术架构**

- 数据应用：实时大屏、移动BI、PC报表、自助分析
- 数据仓库：Doris数仓
- 数据源：SAP系统、DRP系统、E3系统、新E3系统、采集系统

**技术实现**

- 批量数据同步：基于DataX实现，将对应数据抽取到本地文件，通过Stream Load方式加载入库。
- 实时数据入库：采用Routine Load模式加载Kafka数据。
- 全增量一体化数据加工：将代码逻辑保存成视图，每一个视图都有一张物理表来存储对应的数据。根据业务日期来控制数据的处理量级。

**数据分层**

- DWD层：明细数据的组合加工，包括行头合并、商品拆箱处理、命名统一、数据粒度统一等。
- DWB层：按照公共维度汇总数据，加工公共维度指标，包括销售吊牌金额、库存吊牌金额等，采用`Duplicate`模型，以业务日期和店仓编码为`Key`字段，以SKC编码为分布键。
- DWS层：将DWB层计算结果宽表化，数据粒度、数据模型、数据分布等跟DWB层保持一致。

### 11.4 技术细节处理

1. 报表展示的数据刷新任务方案：在数据重新写入过程中，可能会有页面查询，导致查到空数据，不能先删除再插入。
    - 继续保留主键，构建`Unique`模型，每次跑批追加当日最新数据。适合几乎不会删除数据的场景。
    - 针对有业务数据删除或者无法构建主键模型的场景，将当日数据写入临时表，从临时表中写入当前表，用户几乎无感知。
    - 针对计算结果是高度汇总，没有合适的`Key`字段做增量删除的场景，使用`Swap`方式。
  
2. 实时大屏数据刷新方案：在前端页面发起查询请求时，如果Redis中数据生成时间在30秒内，不在发起查询，如果超过30秒，则请求Doris查询数据来更新Redis，保证下一次请求数据又快又准确。

### 11.5 选择Doris的好处

1. 查询高效：基本上不需要太多优化，90%页面模块都可以在3秒内完成刷新。
2. 开发简单：数据接入Doris后，不需要二次迁移，降低开发难度。
3. 运维简单：数据通过视图加载，追溯简单，方便快速定位问题。
4. 实时性强：通过30 min的微批处理和秒级延时的实时大屏查询，提升数据时效性。
5. 流批处理结合：Doris同时支持批流处理。