# 第13章 Doris

## 1 Doris简介

Doris是由百度自研并开源的OLAP数据库，支持标准的SQL并完全兼容MySQL协议，仅需亚秒级响应时间即可返回海量数据下的查询结果。

### 1.1 特点

- 极简架构：融合了Google Mesa的数据存储模型、Apache的ORCFile存储格式、Apache Impala的查询引擎和MySQL交互协议。
- 使用简单：
    - 数据建模方面：支持Aggregate、Unique和Duplicate模型。
    - 数据导入方面：多种数据导入方案，在数据导入过程中保证原子操作。
    - SQL应用方面：支持标准的SQL语言，与MySQL兼容。
    - 工具方面：支持用户无缝使用DBeaver、DataGrip、Navicat等主流开发工具。
    - 集群可靠性方面：使用内存存储+检查点+镜像日志文件模式，使用BTBJE协议实现元数据的高可用和高可靠。
    - 集群扩缩容方面：基于分布式管理框架，自动管理数据副本的分布、修复和均衡。
    - 集群升级方面：只需要替换二进制程序，滚动重启集群即可。
- 功能丰富：
    - 分区分桶裁剪功能：第一层是分区，支持Range和List的划分方式；第二层是分桶，将数据通过Hash值进行水平划分，数据分片（Tablet）在集群中被均匀打散。
    - Bitmap数据类型：利用位图存储整型数据，进行集合操作。
    - 物化视图：满足用户对原始明细数据任意维度分析，快速对固定维度进行分析、查询。
- 开源开放：支持Apache License 2.0协议。
  
### 1.2 核心设计

- 存储引擎：
    - 针对不同的数据类型，提供不同的编码方式。
    - 支持最大空间为256MB的Segment，按列存储数据，每一列分为多个Page。
    - 提供两种索引：智能索引、二级索引
- 查询引擎：
    - 基于MPP框架的火山模型：基于SQL语句生成逻辑执行计划，根据数据分布，形成物理执行计划。
    - Agg阶段：重分布数据、汇总数据
- 查询优化器：基于规则和基于代价的查询优化，优化改进方面为常量折叠、子查询改写、提取公共表达式、智能预过滤、谓词下推。
- 向量化执行引擎：高效的向量数据结构（Vector） + 批量化处理数据（nextBatch） + Batch内性能优化（SIMD）

### 1.3 应用场景

- 实时大屏：对接Kafka和Flink，实现实时数据查询
- 固定报表：基于明细数据或者轻度汇总数据直接进行查询，通过MySQL交互协议支持各种报表工具。
- 自助分析：也称为多维分析，IT人员根据业务需求预先加工好维度数据和事实数据，供业务人员按照自由组合维度进行数据分析。提供丰富的Join操作和高效的Join查询，基于行列混合存储数据，仅需读取部分列进行计算。
- 用户画像：支持Bitmap去重，更优雅、快速地筛选用户。
- 多源联邦查询：通过Multi-Catalog功能，快速接入多种数据源。
- 实时数据仓库：利用Canal解析MySQL的binlog日志，利用Flume采集Web日志，最终写入Kafka并进行削峰填谷，提供稳定的数据流。Kafka数据直接通过Routine Load进入Doris，也可以经由Flink加工处理后写入Doris，通过视图或物化视图进行数据处理，由前端应用直接查询实时数据。

## 2 Doris部署

### 2.1 下载软件包

访问[Doris官网](https://doris.apache.org/download/)，下载最新的软件包`apache-doris-1.2.7-bin-x64.tar.xz`，在`/data/soft`目录下解压：
```shell
cd /data/soft
tar -xvf apache-doris-1.2.7-bin-x64.tar.xz
```

### 2.2 配置FE

1. 创建元数据目录
```shell
mkdir -p /data/doris/doris-meta
```

2. 修改`fe.conf`配置文件

在`/data/soft/apache-doris-1.2.7-bin-x64/fe/conf/fe.conf`文件中添加以下内容：
```properties
priority_networks=192.168.56.0/24
meta_dir=/data/doris/doris-meta
```

其中`priority_networks`表示FE的节点地址，`meta_dir`表示元数据目录。

### 2.3 启动FE

1. 启动FE

```shell
cd /data/soft/apache-doris-1.2.7-bin-x64/fe
./bin/start_fe.sh --daemon
```

2. 访问元数据管理页面

页面地址：http://192.168.56.101:8030/，使用`root`用户登录，密码为空。

3. 使用DataGrip连接数据库，配置MySQL连接

连接信息如下：
```text
host: 192.168.56.101
port: 9030
User: root
```

4. 验证FE是否启动正常

```genericsql
show frontends
```

如看到`Alive`为`true`，则FE节点启动正常。

### 2.3 配置BE

1. 创建数据存储目录

```shell
mkdir -p /data/doris/storage
```

2. 修改`be.conf`配置文件

在`/data/soft/apache-doris-1.2.7-bin-x64/be/conf/be.conf`文件中添加以下内容：
```properties
priority_networks=192.168.56.0/24
storage_root_path=/data/doris/storage
JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64
```

其中`priority_networks`表示BE的节点地址，`storage_root_path`表示数据存储目录。

3. 修改系统参数

```shell
sysctl -w vm.max_map_count=2000000
ulimit -n 65536
```

### 2.4 启动BE

1. 启动BE

```shell
cd /data/soft/apache-doris-1.2.7-bin-x64/be
./bin/start_be.sh --daemon
```

2. 添加BE节点到集群

在MySQL查询窗口中，执行以下代码：
```genericsql
alter system add backend "192.168.56.101:9050";
```

3. 验证BE是否启动正常

```genericsql
show backends
```

如看到`Alive`为`true`，则BE节点启动正常。

### 2.5 修改默认用户`root`的密码

在MySQL查询窗口中，执行以下代码设置密码为root：
```genericsql
set password for 'root'=password('root')
```

## 3 Doris数据对象

### 3.1 数据类型

- 数值类型：TINTINT、SMALLINT、INT、BIGINT、LARGEINT、FLOAT、DOUBLE、DECIMAL
- 日期时间类型：DATE、DATETIME
- 字符串类型：CHAR、VARCHAR、TEXT
- BITMAP类型：只能用于`Aggregate`数据模型的表，不能用在`Key`列，建表时需搭配`BITMAP_UNION`使用。
- HLL类型：只能用于`Aggregate`数据模型的表，不能用在`Key`列，建表时需搭配`HLL_UNION`使用。
- BOOLEAN类型：建议用`CHAR(1)`或`VARCHAR(1)`代替

### 3.2 外部表引擎

- MySQL表引擎
- Broker表引擎：用于读取外部数据文件映射成Doris数据库的外部表，支持读取HDFS、S3、BOS等存储系统上的文件。文件名中的逗号用`%2c`代替，`%`用`%25`代替。
- Hive表引擎
- Iceberg表引擎

### 3.3 函数

- 日期函数：TIME_ROUND
- 正则匹配函数：REGEXP（正向匹配）、REGEXP_EXTRACT（提取）、REGEXP_REPLACE（替换）、NOT REGEXP（反向匹配）
- BITMAP函数：BITMAP_EMPTY、BITMAP_HASH、BITMAP_UNION
- JSON函数：get_json_double()、get_json_int()、get_json_string()
- 表函数：将一条记录转换成多条记录，包括EXPLODE_BITMAP、EXPLODE_SPLIT、EXPLODE_JSON_ARRAY、
- 窗口函数：每个窗口内的数据可以用OVER从句进行排序和分组。

## 4 Doris数据模型

### 4.1 数据聚合过程

Aggregate模型和Unique模型的数据聚合过程：

1. 数据写入阶段：针对每一个批次的导入数据，先在批次内进行数据合并。
2. 节点数据压实阶段：在数据写入后，BE节点不定期进行跨批次的数据合并。
3. 数据查询阶段：对于涉及查询的数据，会进行进一步聚合，避免返回错误的结果。

### 4.2 数据模型应用场景

- Aggregate模型：适合有固定模式的报表类查询场景。
- Unique模型：针对需要唯一主键约束的场景，适合数仓的ODS层。
- Duplicate模型：适合任意维度的Ad-hoc查询。

### 4.3 ORCFile

**存储格式：**

- Index Data：存储某Stripe上数据的位置、总行数等信息。
- Row Data：以Stream的形式存储数据信息。
- Stripe Footer：存储某Stripe的统计结果，包括Max、Min、count等信息。
- File Footer：存储表的统计结果，以及各Stripe的位置信息。
- Postscript：存储表的行数、压缩参数、压缩大小、列等信息。

**优点：**

- 数据切块：按照分区数+数据块切分
- 压缩策略：块内按照列存储方式压缩
- 字典压缩：支持
- 数据压缩比：压缩比一般为7:1左右
- 数据写入：适合批量写入
- 数据读取：整行读取和部分字段读取效率都比较高
- 数据更新：支持按照索引更新
- 数据删除：支持按照索引删除
- 索引：效果非常好

### 4.4 分区分桶原则

- Tablet数量原则：在不考虑扩容的情况下，一个表的Tablet数量略多于整个集群的磁盘数量。
- Tablet数据量原则（优先）：单个Tablet的数据量大小设置在1G\~10G内，单个Tablet数据量过小，数据聚合效果不佳，元数据管理压力大；如果数据量过大，不利于副本的迁移、补齐，会提高Schema变更或者Rollup操作失败的概率。

### 4.5 DDL语句执行过程

1. 用户发起DDL语句执行请求，提交给FE节点。
2. 识别命令类型：FE启动事件监听器来监听用户的连接，命令类型包括初始化数据连接、端口连接、SQL语句执行。
3. 词法和语法解析：词法解析是判断单词的正确性，语法解析是判断多个单词组合在一个是否为一个合法的操作命令。
4. DDL语句执行
5. 元数据修改：修改Catalog数据和通知BE节点创建对应的文件夹。
6. 元数据持久化：把修改信息持久化到日志文件中，以便数据库重启后可以通过回放恢复对应的元数据。

## 5 数据导入

### 5.1 Stream Load执行流程

1. 用户提交`Stream Load`请求到节点（`FE`或`BE`）。
2. 接收到请求后，进行`Header`解析（解析数据导入的库、表、`Label`等信息），进行用户鉴权，`FE`节点将`Stream Load`请求转发到一个`BE`节点，`BE`节点作为本次任务的协调者（Coordinator）。
3. `Coordinator BE`进行`Header`解析（解析数据的文件格式、消息体的大小、超时时间、用户鉴权信息等），数据校验。
4. `Coordinator BE`通过`Thrift RPC`向`FE`节点发送`Begin Transaction`请求。
5. `FE`节点开启一个事务，并向`Coordinator BE`返回事务ID。
6. `Coordinator BE`收到事务ID，通过`Thrift RPC`向`FE`节点发送获取导入计划的请求。
7. `FE`节点为任务生成导入计划，返回给`Coordinator BE`。
8. `Coordinator BE`执行导入计划，将接收传来的实时数据通过`BRPC`分发给其他`Executor BE`。
9. 其他`Executor BE`将数据写入存储层。
10. `Coordinator BE`通过`Thrift RPC`向`FE`节点发送`Commit Transaction`请求。
11. `FE`节点对事务进行提交，向`Executor BE`发送`Publish Version`任务，等待执行完成。
12. `Executor BE`异步执行，将数据导入时生成的`Rowset`变为可见数据版本。
13. 当`Publish Version`任务正常完成，`FE`向`Coordinator BE`返回`Commit Transaction`和`Publish Version`任务结果。
14. `Coordinator BE`向用户返回`Stream Load`执行的最终结果。